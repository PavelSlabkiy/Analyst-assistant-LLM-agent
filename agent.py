"""
LLM Analytics Assistant module.
Generates and executes Python code for data analysis based on user prompts.
"""
import io
import traceback
from dataclasses import dataclass
from typing import Any, Dict, Optional

import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for server environments
import matplotlib.pyplot as plt
from openai import OpenAI


@dataclass
class AssistantResponse:
    """Response from the assistant containing text and optional attachments."""
    text: str
    image_bytes: Optional[bytes] = None
    xlsx_bytes: Optional[bytes] = None
    xlsx_filename: str = "data_export.xlsx"


class LLMAnalystAssistant:
    """
    An AI-powered analytics assistant that interprets natural language queries
    and executes Python code for data analysis.
    """
    
    def __init__(
        self,
        df: pd.DataFrame,
        openrouter_api_key: str,
        metadata: Dict,
        model: str = "kwaipilot/kat-coder-pro:free",
        verbose: bool = False,
    ):
        """
        Initialize the analytics assistant.
        
        Args:
            df: The pandas DataFrame to analyze
            openrouter_api_key: API key for OpenRouter
            metadata: Dictionary describing the DataFrame structure
            model: LLM model identifier
            verbose: Whether to print debug information
        """
        self.df = df
        self.model = model
        self.verbose = verbose
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=openrouter_api_key,
        )
        self.metadata = metadata

    def ask(self, user_prompt: str) -> AssistantResponse:
        """
        Process a user's question and return an answer.
        
        Args:
            user_prompt: The user's question in natural language
            
        Returns:
            AssistantResponse with text and optional image/xlsx attachments
        """
        if self.verbose:
            print("\n[USER]", user_prompt)

        messages = [
            {
                "role": "system",
                "content": self._system_prompt(self._build_metadata()),
            },
            {
                "role": "user",
                "content": user_prompt,
            },
        ]

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0,
            stream=False,
        )

        content = response.choices[0].message.content.strip()

        if self.verbose:
            print("\n[LLM RESPONSE]")
            print(content)

        # If LLM returned code
        if self._looks_like_code(content):
            code = self._extract_code(content)

            if self.verbose:
                print("\n[CODE TO EXECUTE]")
                print(code)

            result = self._run_with_repair_loop(
                initial_code=code,
                messages=messages,
                max_iterations=3,
            )

            if self.verbose:
                print("\n[RESULT]")
                print(result.text)

            return result

        # Plain text response
        return AssistantResponse(text=content)

    def _run_with_repair_loop(
        self,
        initial_code: str,
        messages: list,
        max_iterations: int = 3,
    ) -> AssistantResponse:
        """
        Execute code with automatic error repair loop.
        
        Args:
            initial_code: The initial Python code to execute
            messages: Conversation history for context
            max_iterations: Maximum repair attempts
            
        Returns:
            AssistantResponse with results
        """
        code = initial_code

        for iteration in range(max_iterations):
            try:
                # Create isolated namespace with necessary imports
                namespace = {
                    "df": self.df,
                    "pd": pd,
                    "plt": plt,
                    "io": io,
                    "__builtins__": __builtins__,
                }

                # Close any existing figures
                plt.close('all')
                
                exec(code, namespace, namespace)

                if "result" not in namespace:
                    raise ValueError("Variable `result` not found in code output")

                result = namespace["result"]
                
                # Check if result is a DataFrame (for xlsx export)
                xlsx_bytes = None
                xlsx_filename = "data_export.xlsx"
                if isinstance(result, pd.DataFrame):
                    xlsx_bytes, xlsx_filename = self._create_xlsx(result)
                    text_result = f"–¢–∞–±–ª–∏—Ü–∞ —Å {len(result)} —Å—Ç—Ä–æ–∫–∞–º–∏ –≥–æ—Ç–æ–≤–∞ –∫ —Å–∫–∞—á–∏–≤–∞–Ω–∏—é"
                else:
                    text_result = str(result)
                
                # Check if a plot was created
                image_bytes = self._capture_plot()

                return AssistantResponse(
                    text=text_result,
                    image_bytes=image_bytes,
                    xlsx_bytes=xlsx_bytes,
                    xlsx_filename=xlsx_filename,
                )

            except Exception:
                error_text = traceback.format_exc()

                if self.verbose:
                    print(f"\n[ERROR | iteration {iteration + 1}]")
                    print(error_text)

                if iteration == max_iterations - 1:
                    return AssistantResponse(
                        text=(
                            "ü§î –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –±–æ—Ç –ø–æ–∫–∞ –Ω–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å.\n\n"
                            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –¥—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å."
                        )
                    )

                # Ask the model to fix the code
                messages.append(
                    {
                        "role": "assistant",
                        "content": f"–í–æ—Ç –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –Ω–∞–ø–∏—Å–∞–ª:\n```python\n{code}\n```",
                    }
                )
                messages.append(
                    {
                        "role": "user",
                        "content": (
                            "–í —ç—Ç–æ–º –∫–æ–¥–µ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞:\n"
                            f"```text\n{error_text}\n```\n\n"
                            "–ò—Å–ø—Ä–∞–≤—å –∫–æ–¥. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π Python-–∫–æ–¥. "
                            "–ò—Å–ø–æ–ª—å–∑—É–π df –∏ —Å–æ—Ö—Ä–∞–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é result."
                        ),
                    }
                )

                repair_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0,
                    stream=False,
                )

                code = self._extract_code(
                    repair_response.choices[0].message.content
                )

                if self.verbose:
                    print("\n[REPAIRED CODE]")
                    print(code)

        return AssistantResponse(
            text=(
                "ü§î –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –±–æ—Ç –ø–æ–∫–∞ –Ω–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å.\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –¥—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å."
            )
        )

    def _create_xlsx(self, df: pd.DataFrame) -> tuple[bytes, str]:
        """
        Create an Excel file from a DataFrame.
        
        Args:
            df: DataFrame to export
            
        Returns:
            Tuple of (xlsx bytes, filename)
        """
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='–î–∞–Ω–Ω—ã–µ')
        buf.seek(0)
        
        # Generate filename based on columns
        cols = '_'.join(df.columns[:2].tolist())[:30] if len(df.columns) > 0 else 'data'
        cols = ''.join(c if c.isalnum() or c == '_' else '_' for c in cols)
        filename = f"{cols}_export.xlsx"
        
        return buf.getvalue(), filename

    def _capture_plot(self) -> Optional[bytes]:
        """
        Capture the current matplotlib figure as PNG bytes.
        
        Returns:
            PNG image bytes or None if no figure exists
        """
        fig = plt.gcf()
        if fig.get_axes():  # Check if figure has any axes (i.e., a plot was created)
            buf = io.BytesIO()
            fig.savefig(buf, format='png', dpi=150, bbox_inches='tight')
            buf.seek(0)
            plt.close('all')
            return buf.getvalue()
        return None

    def _system_prompt(self, metadata: str) -> str:
        """Generate the system prompt for the LLM."""
        return f"""
–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–∞–Ω–Ω—ã–º –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö –∏ –∑–∞—Ä–ø–ª–∞—Ç–∞—Ö.

–£ —Ç–µ–±—è –µ—Å—Ç—å pandas DataFrame `df` —Å –¥–∞–Ω–Ω—ã–º–∏.

{metadata}

–ü–†–ê–í–ò–õ–ê (–°–¢–†–û–ì–û):

1. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –û–î–ù–û–ì–û —á–∏—Å–ª–∞ (—Å—Ä–µ–¥–Ω–µ–µ, –º–µ–¥–∏–∞–Ω–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, —Å—É–º–º–∞):
   - –í–µ—Ä–Ω–∏ Python-–∫–æ–¥, –≥–¥–µ result = —á–∏—Å–ª–æ –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å —á–∏—Å–ª–æ–º
   - –ü—Ä–∏–º–µ—Ä: result = df['salary_display_from'].mean()

2. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ì–†–ê–§–ò–ö (—Å–ª–æ–≤–∞: –≥—Ä–∞—Ñ–∏–∫, –¥–∏–∞–≥—Ä–∞–º–º–∞, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è, –ø–æ–∫–∞–∂–∏ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ):
   - –ò—Å–ø–æ–ª—å–∑—É–π matplotlib (plt)
   - –ù–∞—Å—Ç—Ä–æ–π —à—Ä–∏—Ñ—Ç—ã: plt.rcParams['font.family'] = 'DejaVu Sans'
   - –î–æ–±–∞–≤—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ø–æ–¥–ø–∏—Å–∏ –æ—Å–µ–π
   - –ò—Å–ø–æ–ª—å–∑—É–π plt.figure(figsize=(10, 6))
   - result = "–ì—Ä–∞—Ñ–∏–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω"

3. –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –¢–ê–ë–õ–ò–¶–ê, –í–´–ì–†–£–ó–ö–ê, –≠–ö–°–ü–û–†–¢, –°–ü–ò–°–û–ö, –î–ò–ù–ê–ú–ò–ö–ê, –¢–û–ü (–±–µ–∑ –≥—Ä–∞—Ñ–∏–∫–∞):
   - –°–ª–æ–≤–∞-—Ç—Ä–∏–≥–≥–µ—Ä—ã: —Ç–∞–±–ª–∏—Ü–∞, –≤—ã–≥—Ä—É–∑–∏, —ç–∫—Å–ø–æ—Ä—Ç, —Å–ø–∏—Å–æ–∫, –ø–æ–∫–∞–∂–∏ –¥–∞–Ω–Ω—ã–µ, —Ç–æ–ø-N, –¥–∏–Ω–∞–º–∏–∫–∞, –ø–æ –º–µ—Å—è—Ü–∞–º, –ø–æ –¥–Ω—è–º
   - result –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å DataFrame (pd.DataFrame)
   - –ü—Ä–∏–º–µ—Ä: result = df[['position', 'salary_display_from']].head(10)
   - –ü—Ä–∏–º–µ—Ä: result = df.groupby('city').agg({{'salary_display_from': 'mean'}}).reset_index()

4. –ï—Å–ª–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–µ –Ω—É–∂–Ω—ã ‚Äî –≤–µ—Ä–Ω–∏ —Ç–µ–∫—Å—Ç –±–µ–∑ –∫–æ–¥–∞.

–§–û–†–ú–ê–¢ –ö–û–î–ê:
```python
<—Ç–≤–æ–π –∫–æ–¥>```

–í–ê–ñ–ù–û:
- –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `result`
- –î–ª—è —Ç–∞–±–ª–∏—Ü: result = DataFrame
- –î–ª—è —á–∏—Å–µ–ª: result = —á–∏—Å–ª–æ –∏–ª–∏ f-—Å—Ç—Ä–æ–∫–∞
- –î–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤: result = "–ì—Ä–∞—Ñ–∏–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω"
"""

    def _build_metadata(self) -> str:
        """Build metadata description string from metadata dictionary."""
        lines = ["–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:"]
        for key, value in self.metadata.items():
            lines.append(
                f"- `{key}`: {value.get('description', 'N/A')} "
                f"(—Ç–∏–ø: {value.get('type', 'N/A')}, –ø—Ä–∏–º–µ—Ä: {value.get('sample', 'N/A')})"
            )
        return "\n".join(lines)

    @staticmethod
    def _looks_like_code(text: str) -> bool:
        """Check if the response looks like code."""
        return "```" in text

    @staticmethod
    def _extract_code(text: str) -> str:
        """Extract Python code from markdown code blocks."""
        # Handle ```python ... ``` format
        if "```python" in text:
            parts = text.split("```python")
            if len(parts) > 1:
                code_part = parts[1].split("```")[0]
                return code_part.strip()
        
        # Handle ``` ... ``` format
        if "```" in text:
            parts = text.split("```")
            if len(parts) >= 2:
                return parts[1].strip()
        
        return text.strip()
