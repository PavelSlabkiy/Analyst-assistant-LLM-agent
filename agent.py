"""
LLM Analytics Assistant module.
Generates and executes Python code for data analysis based on user prompts.
"""
import io
import traceback
from dataclasses import dataclass
from typing import Any, Dict, Optional

import pandas as pd
import matplotlib
matplotlib.use('Agg')  # Use non-interactive backend for server environments
import matplotlib.pyplot as plt
from openai import OpenAI


@dataclass
class AssistantResponse:
    """Response from the assistant containing text and optional attachments."""
    text: str
    image_bytes: Optional[bytes] = None
    xlsx_bytes: Optional[bytes] = None
    xlsx_filename: str = "data_export.xlsx"


@dataclass
class ExecutionResult:
    """Internal result from code execution."""
    raw_result: Any
    result_type: str  # "number", "chart", "table", "text"
    code: str = ""
    image_bytes: Optional[bytes] = None
    xlsx_bytes: Optional[bytes] = None
    xlsx_filename: str = "data_export.xlsx"
    dataframe_info: str = ""  # Info about DataFrame columns/rows
    success: bool = True
    error_message: str = ""


class LLMAnalystAssistant:
    """
    An AI-powered analytics assistant that interprets natural language queries
    and executes Python code for data analysis.
    """
    
    # Model for code generation
    CODE_MODEL = "kwaipilot/kat-coder-pro:free"
    # Model for natural language response formatting
    FORMATTER_MODEL = "google/gemma-3-4b-it:free"
    
    def __init__(
        self,
        df: pd.DataFrame,
        openrouter_api_key: str,
        metadata: Dict,
        model: str = "kwaipilot/kat-coder-pro:free",
        formatter_model: str = "google/gemma-3-4b-it:free",
        verbose: bool = False,
    ):
        """
        Initialize the analytics assistant.
        
        Args:
            df: The pandas DataFrame to analyze
            openrouter_api_key: API key for OpenRouter
            metadata: Dictionary describing the DataFrame structure
            model: LLM model for code generation
            formatter_model: LLM model for response formatting
            verbose: Whether to print debug information
        """
        self.df = df
        self.model = model
        self.formatter_model = formatter_model
        self.verbose = verbose
        self.client = OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=openrouter_api_key,
        )
        self.metadata = metadata

    def ask(self, user_prompt: str) -> AssistantResponse:
        """
        Process a user's question and return an answer.
        
        Args:
            user_prompt: The user's question in natural language
            
        Returns:
            AssistantResponse with text and optional image/xlsx attachments
        """
        if self.verbose:
            print("\n[USER]", user_prompt)

        messages = [
            {
                "role": "system",
                "content": self._system_prompt(self._build_metadata()),
            },
            {
                "role": "user",
                "content": user_prompt,
            },
        ]

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=0,
            stream=False,
        )

        content = response.choices[0].message.content.strip()

        if self.verbose:
            print("\n[LLM RESPONSE]")
            print(content)

        # If LLM returned code
        if self._looks_like_code(content):
            code = self._extract_code(content)

            if self.verbose:
                print("\n[CODE TO EXECUTE]")
                print(code)

            exec_result = self._run_with_repair_loop(
                initial_code=code,
                messages=messages,
                max_iterations=3,
            )

            # Format the response using the formatter model
            formatted_text = self._format_response(user_prompt, exec_result)

            if self.verbose:
                print("\n[FORMATTED RESULT]")
                print(formatted_text)

            return AssistantResponse(
                text=formatted_text,
                image_bytes=exec_result.image_bytes,
                xlsx_bytes=exec_result.xlsx_bytes,
                xlsx_filename=exec_result.xlsx_filename,
            )

        # Plain text response - still format it nicely
        return AssistantResponse(text=content)

    def _format_response(self, user_question: str, exec_result: ExecutionResult) -> str:
        """
        Format the execution result into a natural language response.
        
        Args:
            user_question: Original user question
            exec_result: Result from code execution
            
        Returns:
            Formatted natural language response
        """
        if not exec_result.success:
            return exec_result.error_message
        
        # Build MINIMAL context for the formatter (avoid token overflow)
        if exec_result.result_type == "number":
            context = f"–í–æ–ø—Ä–æ—Å: {user_question}\n–†–µ–∑—É–ª—å—Ç–∞—Ç: {exec_result.raw_result}"
        elif exec_result.result_type == "chart":
            context = f"–í–æ–ø—Ä–æ—Å: {user_question}"
        elif exec_result.result_type == "table":
            context = f"–í–æ–ø—Ä–æ—Å: {user_question}\n–¢–∞–±–ª–∏—Ü–∞: {exec_result.dataframe_info}"
        else:
            return str(exec_result.raw_result)

        # Create formatting prompt
        format_prompt = self._get_formatter_prompt(exec_result.result_type)
        
        try:
            response = self.client.chat.completions.create(
                model=self.formatter_model,
                messages=[
                    {"role": "system", "content": format_prompt},
                    {"role": "user", "content": context},
                ],
                temperature=0.3,
                max_tokens=200,  # Limit output tokens
                stream=False,
            )
            
            formatted = response.choices[0].message.content.strip()
            
            if self.verbose:
                print("\n[FORMATTER RESPONSE]")
                print(formatted)
            
            return formatted
            
        except Exception as e:
            if self.verbose:
                print(f"\n[FORMATTER ERROR] {e}")
            # Fallback to raw result if formatting fails
            return str(exec_result.raw_result)

    def _get_formatter_prompt(self, result_type: str) -> str:
        """Get the system prompt for the formatter based on result type."""
        
        if result_type == "number":
            return """–°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π –æ—Ç–≤–µ—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
–§–æ—Ä–º–∞—Ç–∏—Ä—É–π —á–∏—Å–ª–∞: –ø—Ä–æ–±–µ–ª—ã –≤ —Ç—ã—Å—è—á–∞—Ö (150 000), –ø—Ä–æ—Ü–µ–Ω—Ç—ã (0.15‚Üí15%), –∑–∞—Ä–ø–ª–∞—Ç—ã –≤ ‚ÇΩ.
–ü—Ä–∏–º–µ—Ä: "–°—Ä–µ–¥–Ω—è—è –∑–∞—Ä–ø–ª–∞—Ç–∞ —Å–æ—Å—Ç–∞–≤–ª—è–µ—Ç 185 000 ‚ÇΩ." """

        elif result_type == "chart":
            return """–û–ø–∏—à–∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–Ω—ã–π –≥—Ä–∞—Ñ–∏–∫ –Ω–∞ —Ä—É—Å—Å–∫–æ–º (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
–£–∫–∞–∂–∏ —Ç–∏–ø –≥—Ä–∞—Ñ–∏–∫–∞ –∏ —á—Ç–æ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ. –î–æ–±–∞–≤—å emoji üìä –∏–ª–∏ üìà.
–ü—Ä–∏–º–µ—Ä: "üìä –ü–æ—Å—Ç—Ä–æ–µ–Ω–∞ –¥–∏–∞–≥—Ä–∞–º–º–∞ –∑–∞—Ä–ø–ª–∞—Ç –ø–æ –≥–æ—Ä–æ–¥–∞–º." """

        elif result_type == "table":
            return """–û–ø–∏—à–∏ –≤—ã–≥—Ä—É–∑–∫—É –Ω–∞ —Ä—É—Å—Å–∫–æ–º (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è).
–£–∫–∞–∂–∏ –∫–æ–ª-–≤–æ —Å—Ç—Ä–æ–∫ –∏ –æ—Å–Ω–æ–≤–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏. –£–ø–æ–º—è–Ω–∏ Excel. –î–æ–±–∞–≤—å emoji üìã.
–ü—Ä–∏–º–µ—Ä: "üìã –í—ã–≥—Ä—É–∂–µ–Ω–æ 10 –≤–∞–∫–∞–Ω—Å–∏–π (–ø–æ–∑–∏—Ü–∏—è, –∑–∞—Ä–ø–ª–∞—Ç–∞, –≥–æ—Ä–æ–¥). Excel –ø—Ä–∏–∫—Ä–µ–ø–ª—ë–Ω." """

        return "–û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –Ω–∞ —Ä—É—Å—Å–∫–æ–º."

    def _run_with_repair_loop(
        self,
        initial_code: str,
        messages: list,
        max_iterations: int = 3,
    ) -> ExecutionResult:
        """
        Execute code with automatic error repair loop.
        
        Args:
            initial_code: The initial Python code to execute
            messages: Conversation history for context
            max_iterations: Maximum repair attempts
            
        Returns:
            ExecutionResult with results
        """
        code = initial_code

        for iteration in range(max_iterations):
            try:
                # Create isolated namespace with necessary imports
                namespace = {
                    "df": self.df,
                    "pd": pd,
                    "plt": plt,
                    "io": io,
                    "__builtins__": __builtins__,
                }

                # Close any existing figures
                plt.close('all')
                
                exec(code, namespace, namespace)

                if "result" not in namespace:
                    raise ValueError("Variable `result` not found in code output")

                result = namespace["result"]
                
                # Determine result type and process accordingly
                image_bytes = self._capture_plot()
                xlsx_bytes = None
                xlsx_filename = "data_export.xlsx"
                dataframe_info = ""
                
                if isinstance(result, pd.DataFrame):
                    result_type = "table"
                    xlsx_bytes, xlsx_filename = self._create_xlsx(result)
                    dataframe_info = f"{len(result)} —Å—Ç—Ä–æ–∫, –∫–æ–ª–æ–Ω–∫–∏: {', '.join(result.columns.tolist()[:10])}"
                elif image_bytes:
                    result_type = "chart"
                elif isinstance(result, (int, float)) or (isinstance(result, str) and any(c.isdigit() for c in result)):
                    result_type = "number"
                else:
                    result_type = "text"

                return ExecutionResult(
                    raw_result=result,
                    result_type=result_type,
                    code=code,
                    image_bytes=image_bytes,
                    xlsx_bytes=xlsx_bytes,
                    xlsx_filename=xlsx_filename,
                    dataframe_info=dataframe_info,
                    success=True,
                )

            except Exception:
                error_text = traceback.format_exc()

                if self.verbose:
                    print(f"\n[ERROR | iteration {iteration + 1}]")
                    print(error_text)

                if iteration == max_iterations - 1:
                    return ExecutionResult(
                        raw_result=None,
                        result_type="error",
                        success=False,
                        error_message=(
                            "ü§î –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –±–æ—Ç –ø–æ–∫–∞ –Ω–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å.\n\n"
                            "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –¥—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å."
                        ),
                    )

                # Ask the model to fix the code
                messages.append(
                    {
                        "role": "assistant",
                        "content": f"–í–æ—Ç –∫–æ–¥, –∫–æ—Ç–æ—Ä—ã–π —Ç—ã –Ω–∞–ø–∏—Å–∞–ª:\n```python\n{code}\n```",
                    }
                )
                messages.append(
                    {
                        "role": "user",
                        "content": (
                            "–í —ç—Ç–æ–º –∫–æ–¥–µ –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞:\n"
                            f"```text\n{error_text}\n```\n\n"
                            "–ò—Å–ø—Ä–∞–≤—å –∫–æ–¥. –í–µ—Ä–Ω–∏ –¢–û–õ–¨–ö–û –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π Python-–∫–æ–¥. "
                            "–ò—Å–ø–æ–ª—å–∑—É–π df –∏ —Å–æ—Ö—Ä–∞–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é result."
                        ),
                    }
                )

                repair_response = self.client.chat.completions.create(
                    model=self.model,
                    messages=messages,
                    temperature=0,
                    stream=False,
                )

                code = self._extract_code(
                    repair_response.choices[0].message.content
                )

                if self.verbose:
                    print("\n[REPAIRED CODE]")
                    print(code)

        return ExecutionResult(
            raw_result=None,
            result_type="error",
            success=False,
            error_message=(
                "ü§î –ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –±–æ—Ç –ø–æ–∫–∞ –Ω–µ –∑–Ω–∞–µ—Ç –æ—Ç–≤–µ—Ç–∞ –Ω–∞ —ç—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å.\n\n"
                "–ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –∑–∞–ø—Ä–æ—Å –∏–ª–∏ –∑–∞–¥–∞—Ç—å –¥—Ä—É–≥–æ–π –≤–æ–ø—Ä–æ—Å."
            ),
        )

    def _create_xlsx(self, df: pd.DataFrame) -> tuple[bytes, str]:
        """
        Create an Excel file from a DataFrame.
        
        Args:
            df: DataFrame to export
            
        Returns:
            Tuple of (xlsx bytes, filename)
        """
        buf = io.BytesIO()
        with pd.ExcelWriter(buf, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='–î–∞–Ω–Ω—ã–µ')
        buf.seek(0)
        
        # Generate filename based on columns
        cols = '_'.join(df.columns[:2].tolist())[:30] if len(df.columns) > 0 else 'data'
        cols = ''.join(c if c.isalnum() or c == '_' else '_' for c in cols)
        filename = f"{cols}_export.xlsx"
        
        return buf.getvalue(), filename

    def _capture_plot(self) -> Optional[bytes]:
        """
        Capture the current matplotlib figure as PNG bytes.
        
        Returns:
            PNG image bytes or None if no figure exists
        """
        fig = plt.gcf()
        if fig.get_axes():  # Check if figure has any axes (i.e., a plot was created)
            buf = io.BytesIO()
            fig.savefig(buf, format='png', dpi=150, bbox_inches='tight')
            buf.seek(0)
            plt.close('all')
            return buf.getvalue()
        return None

    def _system_prompt(self, metadata: str) -> str:
        """Generate the system prompt for the LLM."""
        return f"""
–¢—ã ‚Äî –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –ø–æ –¥–∞–Ω–Ω—ã–º –æ –≤–∞–∫–∞–Ω—Å–∏—è—Ö –∏ –∑–∞—Ä–ø–ª–∞—Ç–∞—Ö.

–£ —Ç–µ–±—è –µ—Å—Ç—å pandas DataFrame `df` —Å –¥–∞–Ω–Ω—ã–º–∏.

{metadata}

–ü–†–ê–í–ò–õ–ê (–°–¢–†–û–ì–û):

1. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –û–î–ù–û–ì–û —á–∏—Å–ª–∞ (—Å—Ä–µ–¥–Ω–µ–µ, –º–µ–¥–∏–∞–Ω–∞, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ, —Å—É–º–º–∞):
   - –í–µ—Ä–Ω–∏ Python-–∫–æ–¥, –≥–¥–µ result = —á–∏—Å–ª–æ –∏–ª–∏ —Å—Ç—Ä–æ–∫–∞ —Å —á–∏—Å–ª–æ–º
   - –ü—Ä–∏–º–µ—Ä: result = df['salary_display_from'].mean()

2. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –ì–†–ê–§–ò–ö (—Å–ª–æ–≤–∞: –≥—Ä–∞—Ñ–∏–∫, –¥–∏–∞–≥—Ä–∞–º–º–∞, –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è, –ø–æ–∫–∞–∂–∏ –Ω–∞ –≥—Ä–∞—Ñ–∏–∫–µ):
   - –ò—Å–ø–æ–ª—å–∑—É–π matplotlib (plt)
   - –ù–∞—Å—Ç—Ä–æ–π —à—Ä–∏—Ñ—Ç—ã: plt.rcParams['font.family'] = 'DejaVu Sans'
   - –î–æ–±–∞–≤—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ –∏ –ø–æ–¥–ø–∏—Å–∏ –æ—Å–µ–π
   - –ò—Å–ø–æ–ª—å–∑—É–π plt.figure(figsize=(10, 6))
   - result = "–ì—Ä–∞—Ñ–∏–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω"

3. –ï—Å–ª–∏ –Ω—É–∂–Ω–∞ –¢–ê–ë–õ–ò–¶–ê, –í–´–ì–†–£–ó–ö–ê, –≠–ö–°–ü–û–†–¢, –°–ü–ò–°–û–ö, –î–ò–ù–ê–ú–ò–ö–ê, –¢–û–ü (–±–µ–∑ –≥—Ä–∞—Ñ–∏–∫–∞):
   - –°–ª–æ–≤–∞-—Ç—Ä–∏–≥–≥–µ—Ä—ã: —Ç–∞–±–ª–∏—Ü–∞, –≤—ã–≥—Ä—É–∑–∏, —ç–∫—Å–ø–æ—Ä—Ç, —Å–ø–∏—Å–æ–∫, –ø–æ–∫–∞–∂–∏ –¥–∞–Ω–Ω—ã–µ, —Ç–æ–ø-N, –¥–∏–Ω–∞–º–∏–∫–∞, –ø–æ –º–µ—Å—è—Ü–∞–º, –ø–æ –¥–Ω—è–º
   - result –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å DataFrame (pd.DataFrame)
   - –ü—Ä–∏–º–µ—Ä: result = df[['position', 'salary_display_from']].head(10)
   - –ü—Ä–∏–º–µ—Ä: result = df.groupby('city').agg({{'salary_display_from': 'mean'}}).reset_index()

4. –ï—Å–ª–∏ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –Ω–µ –Ω—É–∂–Ω—ã ‚Äî –≤–µ—Ä–Ω–∏ —Ç–µ–∫—Å—Ç –±–µ–∑ –∫–æ–¥–∞.

–§–û–†–ú–ê–¢ –ö–û–î–ê:
```python
<—Ç–≤–æ–π –∫–æ–¥>```

–í–ê–ñ–ù–û:
- –í—Å–µ–≥–¥–∞ —Å–æ—Ö—Ä–∞–Ω—è–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é `result`
- –î–ª—è —Ç–∞–±–ª–∏—Ü: result = DataFrame
- –î–ª—è —á–∏—Å–µ–ª: result = —á–∏—Å–ª–æ –∏–ª–∏ f-—Å—Ç—Ä–æ–∫–∞
- –î–ª—è –≥—Ä–∞—Ñ–∏–∫–æ–≤: result = "–ì—Ä–∞—Ñ–∏–∫ –ø–æ—Å—Ç—Ä–æ–µ–Ω"
"""

    def _build_metadata(self) -> str:
        """Build metadata description string from metadata dictionary."""
        lines = ["–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö:"]
        for key, value in self.metadata.items():
            lines.append(
                f"- `{key}`: {value.get('description', 'N/A')} "
                f"(—Ç–∏–ø: {value.get('type', 'N/A')}, –ø—Ä–∏–º–µ—Ä: {value.get('sample', 'N/A')})"
            )
        return "\n".join(lines)

    @staticmethod
    def _looks_like_code(text: str) -> bool:
        """Check if the response looks like code."""
        return "```" in text

    @staticmethod
    def _extract_code(text: str) -> str:
        """Extract Python code from markdown code blocks."""
        # Handle ```python ... ``` format
        if "```python" in text:
            parts = text.split("```python")
            if len(parts) > 1:
                code_part = parts[1].split("```")[0]
                return code_part.strip()
        
        # Handle ``` ... ``` format
        if "```" in text:
            parts = text.split("```")
            if len(parts) >= 2:
                return parts[1].strip()
        
        return text.strip()
