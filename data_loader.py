"""
–ú–æ–¥—É–ª—å –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–≥–æ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞.
"""
import json
import re
import subprocess
from pathlib import Path
from typing import Dict, Optional

import numpy as np
import pandas as pd


# –ö–æ–ª–æ–Ω–∫–∏ –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –ø—Ä–∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–µ
COLUMNS_TO_DROP = [
    "type", 
    "offer_type", 
    "description_html", 
    "remote_options", 
    "short_description", 
    "stack_description",
    "short_info",
    "company.logotype",
    "company.url",
    "company.post_to_job_aggregators",
    "recruiter.photo",
    "og.title",
    "og.description",
    "og.image_url",
    "og.image_width",
    "og.image_height",
    "og.site_name",
    "relocation_options",
    "english_level.name",
    "english_level.vacancy_description",
    "one_day_offer_content.version",
    "one_day_offer_content.block_one.header",
    "one_day_offer_content.block_one.last_date",
    "one_day_offer_content.block_one.event_dates",
    "one_day_offer_content.block_one.applications_before",
    "one_day_offer_content.block_two.stack",
    "one_day_offer_content.block_two.header",
    "one_day_offer_content.block_two.short_description",
    "one_day_offer_content.advantages.items",
    "one_day_offer_content.advantages.header",
    "one_day_offer_content_v3.date",
    "one_day_offer_content_v3.teams.items",
    "one_day_offer_content_v3.teams.header",
    "one_day_offer_content_v3.format",
    "one_day_offer_content_v3.schedule.items",
    "one_day_offer_content_v3.schedule.header",
    "one_day_offer_content_v3.block_one.header",
    "one_day_offer_content_v3.block_one.short_description",
    "one_day_offer_content_v3.block_two.stack",
    "one_day_offer_content_v3.block_two.header",
    "one_day_offer_content_v3.block_two.short_description",
    "one_day_offer_content_v3.advantages.items",
    "one_day_offer_content_v3.advantages.header",
    "description",
    "offer_description",
    "analytics_id",
    "office_options",
    "url",
    "company.short_description",
]

# –ö—É—Ä—Å—ã –≤–∞–ª—é—Ç –∫ —Ä—É–±–ª—é
CURRENCY_RATES = {
    '‚ÇΩ': 1,
    '$': 80,
    '‚Ç¨': 94,
}


def download_data_from_gdrive(
    url: str = "https://drive.google.com/file/d/1v4aDGZsXmNsFAxQ9D7IoPes-pko7QRzc/view?usp=share_link",
    output_path: str = "data.json"
) -> bool:
    """
    –°–∫–∞—á–∏–≤–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å Google Drive —Å –ø–æ–º–æ—â—å—é gdown.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        url: URL —Ñ–∞–π–ª–∞ –Ω–∞ Google Drive
        output_path: –ü—É—Ç—å –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å–∫–∞—á–∞–Ω–Ω–æ–≥–æ —Ñ–∞–π–ª–∞
        
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        True –µ—Å–ª–∏ —Å–∫–∞—á–∏–≤–∞–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ, –∏–Ω–∞—á–µ False
    """
    try:
        subprocess.run(
            ["gdown", "--fuzzy", url, "-O", output_path],
            check=True,
            capture_output=True
        )
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω—ã –≤ {output_path}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ: {e}")
        return False
    except FileNotFoundError:
        print("‚ùå gdown –Ω–µ –Ω–∞–π–¥–µ–Ω. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –µ–≥–æ –∫–æ–º–∞–Ω–¥–æ–π: pip install gdown")
        return False


def calculate_salary_rub(row: pd.Series, rates: dict = CURRENCY_RATES) -> float:
    """
    –†–∞—Å—á—ë—Ç –∑–∞—Ä–ø–ª–∞—Ç—ã –≤ —Ä—É–±–ª—è—Ö –∏–∑ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –ø–æ–ª–µ–π.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        row: –°—Ç—Ä–æ–∫–∞ DataFrame —Å –ø–æ–ª—è–º–∏ –∑–∞—Ä–ø–ª–∞—Ç—ã
        rates: –°–ª–æ–≤–∞—Ä—å –∫—É—Ä—Å–æ–≤ –≤–∞–ª—é—Ç
        
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        –ó–∞—Ä–ø–ª–∞—Ç–∞ –≤ —Ä—É–±–ª—è—Ö –∏–ª–∏ NaN
    """
    # 1. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏–µ –∑–∞—Ä–ø–ª–∞—Ç—ã
    frm = row.get('salary_display_from')
    to = row.get('salary_display_to')

    if pd.notna(frm) and pd.notna(to):
        salary = (frm + to) / 2
    elif pd.notna(frm):
        salary = frm
    elif pd.notna(to):
        salary = to
    else:
        # –ü—ã—Ç–∞–µ–º—Å—è —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –∏–∑ salary_description
        text = row.get('salary_description')
        if pd.isna(text):
            return np.nan
        
        match = re.search(r'([\d\s]+)\s*(‚ÇΩ|\$|‚Ç¨)', str(text))
        if not match:
            return np.nan
        
        salary = int(match.group(1).replace(' ', ''))

    # 2. –û–ø—Ä–µ–¥–µ–ª—è–µ–º –≤–∞–ª—é—Ç—É
    currency = row.get('salary_currency')

    if pd.isna(currency):
        text = row.get('salary_description')
        if pd.isna(text):
            return np.nan
        
        cur_match = re.search(r'(‚ÇΩ|\$|‚Ç¨)', str(text))
        if not cur_match:
            return np.nan
        
        currency = cur_match.group(1)

    # 3. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ä—É–±–ª–∏
    rate = rates.get(currency)
    if rate is None:
        return np.nan

    return salary * rate


def preprocess_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    –û—á–∏—Å—Ç–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ DataFrame.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        df: –ò—Å—Ö–æ–¥–Ω—ã–π DataFrame
        
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame
    """
    # –£–¥–∞–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç –≤ –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–µ
    cols_to_drop = [col for col in COLUMNS_TO_DROP if col in df.columns]
    if cols_to_drop:
        df = df.drop(columns=cols_to_drop)
        print(f"  ‚Ü≥ –£–¥–∞–ª–µ–Ω–æ {len(cols_to_drop)} –Ω–µ–Ω—É–∂–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫")
    
    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –∑–∞—Ä–ø–ª–∞—Ç—É –≤ —Ä—É–±–ª—è—Ö
    salary_cols = ['salary_display_from', 'salary_display_to', 'salary_description', 'salary_currency']
    if all(col in df.columns for col in ['salary_display_from', 'salary_display_to']):
        print("  ‚Ü≥ –†–∞—Å—á—ë—Ç –∑–∞—Ä–ø–ª–∞—Ç—ã –≤ —Ä—É–±–ª—è—Ö...")
        df['salary'] = df.apply(calculate_salary_rub, axis=1)
        
        # –£–¥–∞–ª—è–µ–º –∏—Å—Ö–æ–¥–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∑–∞—Ä–ø–ª–∞—Ç—ã
        salary_cols_to_drop = [col for col in salary_cols if col in df.columns]
        df = df.drop(columns=salary_cols_to_drop)
        print(f"  ‚Ü≥ –°–æ–∑–¥–∞–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ 'salary', —É–¥–∞–ª–µ–Ω–æ {len(salary_cols_to_drop)} –∏—Å—Ö–æ–¥–Ω—ã—Ö –∫–æ–ª–æ–Ω–æ–∫ –∑–∞—Ä–ø–ª–∞—Ç—ã")
    
    return df


def load_data(data_path: str = "data.json") -> Optional[pd.DataFrame]:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ JSON-–¥–∞–Ω–Ω—ã—Ö –≤ pandas DataFrame.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        data_path: –ü—É—Ç—å –∫ JSON-—Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏
        
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        –û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π DataFrame –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏
    """
    path = Path(data_path)
    
    if not path.exists():
        print(f"‚ö†Ô∏è –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {data_path}")
        print("–ü–æ–ø—ã—Ç–∫–∞ —Å–∫–∞—á–∞—Ç—å —Å Google Drive...")
        
        if not download_data_from_gdrive(output_path=data_path):
            return None
    
    try:
        print(f"üìÇ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ {data_path}...")
        data = pd.read_json(path)
        data = pd.json_normalize(data['data'])
        data = data.dropna(axis=1, how="all")
        print(f"  ‚Ü≥ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(data)} –∑–∞–ø–∏—Å–µ–π, {len(data.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É
        print("üîß –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö...")
        data = preprocess_data(data)
        
        print(f"‚úÖ –ò—Ç–æ–≥–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(data)} –∑–∞–ø–∏—Å–µ–π, {len(data.columns)} –∫–æ–ª–æ–Ω–æ–∫")
        return data
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None


def load_metadata(metadata_path: str = "metadata.json") -> Optional[Dict]:
    """
    –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–∑ JSON-—Ñ–∞–π–ª–∞.
    
    –ê—Ä–≥—É–º–µ–Ω—Ç—ã:
        metadata_path: –ü—É—Ç—å –∫ JSON-—Ñ–∞–π–ª—É —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        –°–ª–æ–≤–∞—Ä—å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –∏–ª–∏ None –ø—Ä–∏ –æ—à–∏–±–∫–µ –∑–∞–≥—Ä—É–∑–∫–∏
    """
    path = Path(metadata_path)
    
    if not path.exists():
        print(f"‚ùå –§–∞–π–ª –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {metadata_path}")
        return None
    
    try:
        with open(path, "r", encoding="utf-8") as f:
            metadata = json.load(f)
        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω—ã –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: {len(metadata)} –ø–æ–ª–µ–π")
        return metadata
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {e}")
        return None


if __name__ == "__main__":
    # –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    df = load_data()
    if df is not None:
        print(f"\n–†–∞–∑–º–µ—Ä DataFrame: {df.shape}")
        print(f"–ö–æ–ª–æ–Ω–∫–∏: {list(df.columns)}")
        print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∑–∞—Ä–ø–ª–∞—Ç–∞–º:")
        print(df['salary'].describe())
    
    metadata = load_metadata()
    if metadata is not None:
        print(f"\n–ü–æ–ª—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö: {list(metadata.keys())}")
